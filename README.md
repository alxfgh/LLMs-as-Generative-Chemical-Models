# Transformers in Chemistry

## Encoder-Decoder Models (T5, T5X, BART)
- Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction. [[PAPER]](https://arxiv.org/abs/1811.02633) [[REPO]](https://github.com/pschwllr/MolecularTransformer)
- Multitask Text and Chemistry T5: Unifying Molecular and Textual Representations via Multi-task Language Modelling. [[PAPER]](https://arxiv.org/abs/2301.12586) [[REPO]](https://github.com/GT4SD/multitask_text_and_chemistry_t5)
- MolT5: Translation between Molecules and Natural Language. [[PAPER]](https://blender.cs.illinois.edu/paper/molt5.pdf) [[REPO]](https://github.com/blender-nlp/MolT5)
- T5Chem: Unified Deep Learning Model for Multitask Reaction Predictions with Explanation. [[PAPER]](https://pubmed.ncbi.nlm.nih.gov/35266390/) [[REPO]](https://yzhang.hpc.nyu.edu/T5Chem)
- MolBART. [[REPO]](https://github.com/MolecularAI/MolBART) [[MODEL]](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/megamolbart)

## Prefix Language Models (BERT, XLNet, etc.)
- ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction. [[PAPER]](https://arxiv.org/abs/2010.09885) [[REPO]](https://github.com/seyonechithrananda/bert-loves-chemistry)
- RXNFP: Mapping the Space of Chemical Reactions using Attention-Based Neural Networks. [[PAPER]](https://chemrxiv.org/engage/chemrxiv/article-details/60c753a0bdbb89acf8a3a4b5) [[REPO]](https://github.com/rxn4chemistry/rxnfp)
- MolBERT: Molecular representation learning with language models and domain-relevant auxiliary tasks. [[PAPER]](https://arxiv.org/abs/2011.13230) [[REPO]](https://github.com/BenevolentAI/MolBERT)
- MoLFormer: Large-Scale Chemical Language Representations Capture Molecular Structure and Properties [[PAPER]](https://arxiv.org/abs/2106.09553) [[REPO]](https://github.com/IBM/molformer)
- Regression Transformer enables concurrent sequence regression and generation for molecular language modelling. [[PAPER]](https://arxiv.org/abs/2202.01338) [[REPO]](https://github.com/IBM/regression-transformer)
- DeLiCaTe: Chemical transformer compression for accelerating both training and inference of molecular modeling. [[PAPER]](https://arxiv.org/ftp/arxiv/papers/2205/2205.07582.pdf) [[REPO]](https://github.com/YiYuDL/DeLiCaTe)

## Causal Decoders (GPT)
- MolGPT: Molecular Generation Using a Transformer-Decoder Model. [[PAPER]](https://chemrxiv.org/engage/chemrxiv/article-details/60c7588e469df48597f456ae) [[REPO]](https://github.com/devalab/molgpt)
- ChemGPT: Neural Scaling of Deep Chemical Models. [[PAPER]](https://chemrxiv.org/engage/chemrxiv/article-details/627bddd544bdd532395fb4b5) [[REPO]](https://github.com/ncfrey/litmatter)
- XYZTransformer: Language models can generate molecules, materials, and protein binding sites directly in three dimensions as XYZ, CIF, and PDB files. [[PAPER]](https://arxiv.org/abs/2305.05708) [[REPO - Currently unavailable]](https://github.com/danielflamshep/xyztransformer)


## Of Interest
- Evaluating the roughness of structure-property relationships using pretrained molecular representations. [[PAPER]](https://arxiv.org/abs/2305.08238)
- Unassisted Noise-Reduction of Chemical Reactions Data Sets. [[PAPER]](https://chemrxiv.org/engage/chemrxiv/article-details/60c75487842e65e86ddb4161)
- Automated Extraction of Chemical Synthesis Actions from Experimental Procedures. [[PAPER]](https://chemrxiv.org/engage/chemrxiv/article-details/60c749fbee301c10e1c79b75)
- Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy. [[PAPER]](https://arxiv.org/abs/1910.08036)
- Neural Scaling of Deep Chemical Models. [[PAPER]](https://chemrxiv.org/engage/chemrxiv/article-details/627bddd544bdd532395fb4b5)
- Graphormer: Do Transformers Really Perform Badly for Graph Representation? [[PAPER]](https://openreview.net/forum?id=OeWooOxFwDa) [[REPO]](https://github.com/microsoft/Graphormer)
- ChemBERTa-2: Towards Chemical Foundation Models. [[PAPER]](https://arxiv.org/abs/2209.01712)
- Social Amnesia - History did not start in 2017. [[BOOK]](https://cominsitu.files.wordpress.com/2021/08/russell-jacoby-social-amnesia-a-critique-of-contemporary-psychology-from-adler-to-laing.pdf)

  
  
   
Curated by Alexander Al-Feghali, PhD Student in the Blum Lab & Cosa Lab at McGill University in Montreal :)  
Last Updated June 10th, 2023.
